{"batch_size"	:	"32",
"double_q"	:	"True",
"env"	:	"<ClippedRewardsWrapper<ProcessFrame84<FireResetEnv<MaxAndSkipEnv<NoopResetEnv<EpisodicLifeEnv<Monitor<TimeLimit<AtariEnv<PongNoFrameskip-v4>>>>>>>>>>",
"exp_name"	:	"",
"exploration"	:	"<dqn_utils.PiecewiseSchedule object at 0x7eff599f6240>",
"frame_history_len"	:	"4",
"gamma"	:	"0.99",
"grad_norm_clipping"	:	"10",
"lander"	:	"False",
"learning_freq"	:	"4",
"learning_starts"	:	"50000",
"optimizer_spec"	:	"OptimizerSpec(constructor=<class 'tensorflow.python.training.adam.AdamOptimizer'>, kwargs={'epsilon': 0.0001}, lr_schedule=<dqn_utils.PiecewiseSchedule object at 0x7eff599f6278>)",
"q_func"	:	"<function atari_model at 0x7effaa168048>",
"replay_buffer_size"	:	"1000000",
"rew_file"	:	"None",
"savedir"	:	"data/d-dqn_PongNoFrameskip-v4_30-07-2019_08-24-26/",
"seed"	:	"1",
"self"	:	"<dqn.QLearner object at 0x7eff599f62b0>",
"session"	:	"<tensorflow.python.client.session.Session object at 0x7eff3d9f1630>",
"stopping_criterion"	:	"<function atari_learn.<locals>.stopping_criterion at 0x7eff3d9ea8c8>",
"suffix"	:	"d-dqn",
"target_update_freq"	:	"10000"}