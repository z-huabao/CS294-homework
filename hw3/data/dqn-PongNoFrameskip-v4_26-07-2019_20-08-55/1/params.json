{"batch_size"	:	"32",
"double_q"	:	"True",
"env"	:	"<ClippedRewardsWrapper<ProcessFrame84<FireResetEnv<MaxAndSkipEnv<NoopResetEnv<EpisodicLifeEnv<Monitor<TimeLimit<AtariEnv<PongNoFrameskip-v4>>>>>>>>>>",
"exploration"	:	"<dqn_utils.PiecewiseSchedule object at 0x7f6c369c1128>",
"frame_history_len"	:	"4",
"gamma"	:	"0.99",
"grad_norm_clipping"	:	"10",
"lander"	:	"False",
"learning_freq"	:	"4",
"learning_starts"	:	"50000",
"optimizer_spec"	:	"OptimizerSpec(constructor=<class 'tensorflow.python.training.adam.AdamOptimizer'>, kwargs={'epsilon': 0.0001}, lr_schedule=<dqn_utils.PiecewiseSchedule object at 0x7f6c369c1160>)",
"q_func"	:	"<function atari_model at 0x7f6c87137048>",
"replay_buffer_size"	:	"1000000",
"rew_file"	:	"None",
"savedir"	:	"data/PongNoFrameskip-v4_26-07-2019_20-08-55/",
"seed"	:	"1",
"self"	:	"<dqn.QLearner object at 0x7f6c369c1198>",
"session"	:	"<tensorflow.python.client.session.Session object at 0x7f6c1a9c0e48>",
"stopping_criterion"	:	"<function atari_learn.<locals>.stopping_criterion at 0x7f6c1a9dc8c8>",
"target_update_freq"	:	"10000"}